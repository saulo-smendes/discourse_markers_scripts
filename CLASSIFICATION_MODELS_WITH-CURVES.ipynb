{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# LDAModel\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# QDAModel\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "# KNNModel\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# NaiveBayesModel\n",
    "from sklearn.naive_bayes import GaussianNB as NaiveBayes\n",
    "# DecisionTreeModel\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "# BaggingModel\n",
    "from sklearn.ensemble import BaggingClassifier as Bagging\n",
    "# AdaBoostModel\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the data from a csv file\n",
    "data = pd.read_csv('/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.5. Classification/results_dm_vfinal_standardized_withf0coeff_20231205.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sample</th>\n",
       "      <th>file</th>\n",
       "      <th>utt</th>\n",
       "      <th>iu</th>\n",
       "      <th>position</th>\n",
       "      <th>dm_text</th>\n",
       "      <th>N_PU</th>\n",
       "      <th>speaker</th>\n",
       "      <th>stressed_vowel</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_min_f0_dm</th>\n",
       "      <th>ratio_max_f0_stressed_dm</th>\n",
       "      <th>ratio_min_f0_stressed_dm</th>\n",
       "      <th>zsil_mean</th>\n",
       "      <th>zsil_stressed_syl</th>\n",
       "      <th>dm_duration</th>\n",
       "      <th>coef_0</th>\n",
       "      <th>coef_1</th>\n",
       "      <th>coef_2</th>\n",
       "      <th>coef_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfamcv01__002__GIL</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bfamcv01</td>\n",
       "      <td>2</td>\n",
       "      <td>CNT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ô</td>\n",
       "      <td>1</td>\n",
       "      <td>GIL</td>\n",
       "      <td>#o</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983107</td>\n",
       "      <td>-0.304754</td>\n",
       "      <td>5.679705</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.108164</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>2.733920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bfamcv01__019__EVN</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bfamcv01</td>\n",
       "      <td>19</td>\n",
       "      <td>EXP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No'</td>\n",
       "      <td>1</td>\n",
       "      <td>EVN</td>\n",
       "      <td>#oh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160827</td>\n",
       "      <td>2.198977</td>\n",
       "      <td>-2.488045</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>-0.029251</td>\n",
       "      <td>-0.369788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfamcv01__048__EVN</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bfamcv01</td>\n",
       "      <td>48</td>\n",
       "      <td>CNT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ô</td>\n",
       "      <td>1</td>\n",
       "      <td>EVN</td>\n",
       "      <td>#oU</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981160</td>\n",
       "      <td>-1.779314</td>\n",
       "      <td>3.764888</td>\n",
       "      <td>2.059</td>\n",
       "      <td>2.059</td>\n",
       "      <td>0.161825</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.011093</td>\n",
       "      <td>0.152832</td>\n",
       "      <td>-0.743381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfamcv01__051__LUI</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bfamcv01</td>\n",
       "      <td>51</td>\n",
       "      <td>EXP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ah</td>\n",
       "      <td>1</td>\n",
       "      <td>LUI</td>\n",
       "      <td>#a</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>1.052422</td>\n",
       "      <td>-3.570504</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.135725</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>-2.202685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bfamcv01__051__LUI</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bfamcv01</td>\n",
       "      <td>51</td>\n",
       "      <td>CNT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>velho</td>\n",
       "      <td>2</td>\n",
       "      <td>LUI</td>\n",
       "      <td>#ehI</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853244</td>\n",
       "      <td>-4.753377</td>\n",
       "      <td>1.759249</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.169890</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.014031</td>\n",
       "      <td>0.194063</td>\n",
       "      <td>-0.918259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>bpubmn01__097__SHE</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bpubmn01</td>\n",
       "      <td>97</td>\n",
       "      <td>ALL</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gente</td>\n",
       "      <td>4</td>\n",
       "      <td>SHE</td>\n",
       "      <td>#eN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569389</td>\n",
       "      <td>-34.570453</td>\n",
       "      <td>-36.209915</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>0.247738</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>-0.076060</td>\n",
       "      <td>1.669450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>bpubmn01__098__SHE</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bpubmn01</td>\n",
       "      <td>98</td>\n",
       "      <td>INP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>porque</td>\n",
       "      <td>1</td>\n",
       "      <td>SHE</td>\n",
       "      <td>#e</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623421</td>\n",
       "      <td>-1.201171</td>\n",
       "      <td>0.799796</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>-0.043119</td>\n",
       "      <td>0.329262</td>\n",
       "      <td>-1.249335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>bpubmn01__110__SHE</td>\n",
       "      <td>OLIVER</td>\n",
       "      <td>bpubmn01</td>\n",
       "      <td>110</td>\n",
       "      <td>CNT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>então o'</td>\n",
       "      <td>1</td>\n",
       "      <td>SHE</td>\n",
       "      <td>#oh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433829</td>\n",
       "      <td>4.263828</td>\n",
       "      <td>-1.451185</td>\n",
       "      <td>-1.414</td>\n",
       "      <td>-1.414</td>\n",
       "      <td>0.093548</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>-0.108439</td>\n",
       "      <td>2.847450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>bpubmn10_13_70417_0_71030_0_NAMES</td>\n",
       "      <td>SAULO</td>\n",
       "      <td>bpubmn10</td>\n",
       "      <td>13</td>\n",
       "      <td>ALL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Junhia</td>\n",
       "      <td>2</td>\n",
       "      <td>Débora</td>\n",
       "      <td>#u</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756404</td>\n",
       "      <td>-5.926195</td>\n",
       "      <td>1.424070</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.265592</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.187648</td>\n",
       "      <td>0.355966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>bpubmn11_74_218151_0_220548_0_NOSSA</td>\n",
       "      <td>SAULO</td>\n",
       "      <td>bpubmn11</td>\n",
       "      <td>74</td>\n",
       "      <td>EXP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nossa</td>\n",
       "      <td>1</td>\n",
       "      <td>Santina</td>\n",
       "      <td>#oh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984479</td>\n",
       "      <td>2.249424</td>\n",
       "      <td>3.527095</td>\n",
       "      <td>-1.081</td>\n",
       "      <td>-1.081</td>\n",
       "      <td>0.301327</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>-0.017306</td>\n",
       "      <td>0.025062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  sample      file  utt   iu  \\\n",
       "0                     bfamcv01__002__GIL  OLIVER  bfamcv01    2  CNT   \n",
       "1                     bfamcv01__019__EVN  OLIVER  bfamcv01   19  EXP   \n",
       "2                     bfamcv01__048__EVN  OLIVER  bfamcv01   48  CNT   \n",
       "3                     bfamcv01__051__LUI  OLIVER  bfamcv01   51  EXP   \n",
       "4                     bfamcv01__051__LUI  OLIVER  bfamcv01   51  CNT   \n",
       "..                                   ...     ...       ...  ...  ...   \n",
       "426                   bpubmn01__097__SHE  OLIVER  bpubmn01   97  ALL   \n",
       "427                   bpubmn01__098__SHE  OLIVER  bpubmn01   98  INP   \n",
       "428                   bpubmn01__110__SHE  OLIVER  bpubmn01  110  CNT   \n",
       "429    bpubmn10_13_70417_0_71030_0_NAMES   SAULO  bpubmn10   13  ALL   \n",
       "430  bpubmn11_74_218151_0_220548_0_NOSSA   SAULO  bpubmn11   74  EXP   \n",
       "\n",
       "     position    dm_text  N_PU  speaker stressed_vowel  ...  ratio_min_f0_dm  \\\n",
       "0         0.0          ô     1      GIL             #o  ...         0.983107   \n",
       "1         0.0        No'     1      EVN            #oh  ...         0.160827   \n",
       "2         0.0          ô     1      EVN            #oU  ...         0.981160   \n",
       "3         0.0         ah     1      LUI             #a  ...         0.001150   \n",
       "4         0.0      velho     2      LUI           #ehI  ...         0.853244   \n",
       "..        ...        ...   ...      ...            ...  ...              ...   \n",
       "426       0.5      gente     4      SHE            #eN  ...         0.569389   \n",
       "427       0.0     porque     1      SHE             #e  ...         0.623421   \n",
       "428       0.0  então o'      1      SHE            #oh  ...         0.433829   \n",
       "429       1.0     Junhia     2   Débora             #u  ...         0.756404   \n",
       "430       0.0      Nossa     1  Santina            #oh  ...         0.984479   \n",
       "\n",
       "     ratio_max_f0_stressed_dm  ratio_min_f0_stressed_dm  zsil_mean  \\\n",
       "0                   -0.304754                  5.679705     -0.142   \n",
       "1                    2.198977                 -2.488045     -0.904   \n",
       "2                   -1.779314                  3.764888      2.059   \n",
       "3                    1.052422                 -3.570504      0.083   \n",
       "4                   -4.753377                  1.759249     -0.004   \n",
       "..                        ...                       ...        ...   \n",
       "426                -34.570453                -36.209915     -1.557   \n",
       "427                 -1.201171                  0.799796      0.525   \n",
       "428                  4.263828                 -1.451185     -1.414   \n",
       "429                 -5.926195                  1.424070     -0.279   \n",
       "430                  2.249424                  3.527095     -1.081   \n",
       "\n",
       "     zsil_stressed_syl  dm_duration    coef_0    coef_1    coef_2    coef_3  \n",
       "0               -0.142     0.108164  0.000017 -0.003885  0.059621  2.733920  \n",
       "1               -0.904     0.147619 -0.000106  0.004373 -0.029251 -0.369788  \n",
       "2                2.059     0.161825  0.000186 -0.011093  0.152832 -0.743381  \n",
       "3                0.083     0.135725 -0.000320  0.010525  0.018429 -2.202685  \n",
       "4               -0.004     0.169890  0.000256 -0.014031  0.194063 -0.918259  \n",
       "..                 ...          ...       ...       ...       ...       ...  \n",
       "426             -1.557     0.247738  0.000061  0.000548 -0.076060  1.669450  \n",
       "427              0.525     0.205259  0.001220 -0.043119  0.329262 -1.249335  \n",
       "428             -1.414     0.093548 -0.000244  0.007431 -0.108439  2.847450  \n",
       "429             -0.279     0.265592  0.000158 -0.000757 -0.187648  0.355966  \n",
       "430             -1.081     0.301327 -0.000183  0.005640 -0.017306  0.025062  \n",
       "\n",
       "[431 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                            0\n",
       "sample                              0\n",
       "file                                0\n",
       "utt                                 0\n",
       "iu                                  0\n",
       "position                            0\n",
       "dm_text                             7\n",
       "N_PU                                0\n",
       "speaker                            38\n",
       "stressed_vowel                      0\n",
       "mean_pitch_dm                       0\n",
       "std_pitch_dm                        0\n",
       "max_pitch_dm                        0\n",
       "min_pitch_dm                        0\n",
       "mean_intensity_dm                   0\n",
       "std_intensity_dm                    0\n",
       "max_intensity_dm                    0\n",
       "min_intensity_dm                    0\n",
       "mean_intensity_stressed_dm          0\n",
       "mean_se_stressed_dm                 0\n",
       "pitch_slope_dm                      0\n",
       "pitch_slope_stressed_dm             0\n",
       "pitch_range_dm                      0\n",
       "pitch_slope_before_stressed_dm      0\n",
       "pitch_slope_after_stressed_dm       1\n",
       "ratio_max_intensity_dm              0\n",
       "ratio_min_intensity_dm              0\n",
       "ratio_max_intensity_stressed_dm     0\n",
       "ratio_min_intensity_stressed_dm     0\n",
       "ratio_max_f0_dm                     0\n",
       "ratio_min_f0_dm                     0\n",
       "ratio_max_f0_stressed_dm            0\n",
       "ratio_min_f0_stressed_dm            0\n",
       "zsil_mean                           1\n",
       "zsil_stressed_syl                   1\n",
       "dm_duration                         0\n",
       "coef_0                              0\n",
       "coef_1                              0\n",
       "coef_2                              0\n",
       "coef_3                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to check if there are any missing values in the data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a column that will encode the dm_text variable and the iu (which is going to be the target variable)\n",
    "data['dm_text_encoded'] = data['dm_text'].astype('category').cat.codes\n",
    "data['iu_encoded'] = data['iu'].astype('category').cat.codes\n",
    "\n",
    "# We need to create a dictionary with the codes and the labels\n",
    "dm_text_dict = dict(enumerate(data['dm_text'].astype('category').cat.categories))\n",
    "iu_dict = dict(enumerate(data['iu'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode y using label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit label encoder\n",
    "le.fit(data['iu'])\n",
    "\n",
    "y = le.transform(data['iu'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ALL', 1: 'CNT', 2: 'EVD', 3: 'EXP', 4: 'INP'}\n"
     ]
    }
   ],
   "source": [
    "# Check the iu_dict and print the correspondig labels and codes\n",
    "print(iu_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Andréa', 1: 'Anete', 2: 'Antônio', 3: 'Bruno', 4: 'Carlão', 5: 'Cristina', 6: 'Cássia', 7: 'Elisa', 8: 'Eustáquio', 9: 'Fernando', 10: 'Flávia', 11: 'GENTE', 12: 'Getúlio', 13: 'Guilherme', 14: 'Heliana', 15: 'Heloísa', 16: 'Jael', 17: 'Janayna', 18: 'João', 19: 'Juliana', 20: 'Junhia', 21: 'Júnia', 22: 'Kelly', 23: 'Kátia', 24: 'Luciana', 25: 'Lívia', 26: 'Maira', 27: 'Marco', 28: 'Marisa', 29: 'Márcia', 30: 'Mércia', 31: 'Ninha', 32: \"No'\", 33: 'Nossa', 34: 'Onofre', 35: 'Plauto', 36: 'Priscila', 37: 'Regina', 38: 'Rena', 39: 'Renato', 40: 'Reninha', 41: 'Sonilde', 42: 'Tommaso', 43: 'Toninho', 44: 'William', 45: 'agora', 46: 'ah', 47: 'ah bom', 48: 'ah não', 49: 'ahn', 50: 'ai', 51: 'aqui', 52: \"aqui o'\", 53: 'aí', 54: 'bem', 55: 'bicho', 56: 'boba', 57: 'bom', 58: 'cara', 59: 'cê sabe', 60: 'cê vê', 61: 'dona Flávia', 62: 'doutor Fernando', 63: 'eh', 64: 'enfim', 65: 'entendeu', 66: 'então', 67: \"então o' \", 68: 'gente', 69: 'hein', 70: 'hhh tá', 71: 'mas', 72: 'mas assim', 73: 'meu filho', 74: 'minha filha', 75: 'mãe', 76: 'não', 77: 'não não', 78: 'né', 79: 'né minha filha', 80: \"o'\", 81: \"o' Bruno\", 82: \"o' Rena\", 83: \"ocê o'\", 84: 'oh', 85: 'olha', 86: \"olha p' cê ver\", 87: 'pera aí', 88: 'pois é', 89: 'porque', 90: 'pô', 91: 'pô Mailton', 92: 'que', 93: 'quer dizer', 94: 'quer ver', 95: 'sabe', 96: 'se bem', 97: 'sim/assim', 98: 'sô', 99: 'tá', 100: 'tá vendo', 101: 'uai', 102: 'uhn', 103: 'ué', 104: 'velho', 105: 'viu', 106: 'viu Carlão', 107: 'viu Zé hhh', 108: 'Éder', 109: 'é', 110: 'é não', 111: 'ô'}\n"
     ]
    }
   ],
   "source": [
    "# Check the dm_text_dict and print the correspondig labels and codes\n",
    "print(dm_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'filename', 1: 'sample', 2: 'file', 3: 'utt', 4: 'iu', 5: 'position', 6: 'dm_text', 7: 'N_PU', 8: 'speaker', 9: 'stressed_vowel', 10: 'mean_pitch_dm', 11: 'std_pitch_dm', 12: 'max_pitch_dm', 13: 'min_pitch_dm', 14: 'mean_intensity_dm', 15: 'std_intensity_dm', 16: 'max_intensity_dm', 17: 'min_intensity_dm', 18: 'mean_intensity_stressed_dm', 19: 'mean_se_stressed_dm', 20: 'pitch_slope_dm', 21: 'pitch_slope_stressed_dm', 22: 'pitch_range_dm', 23: 'pitch_slope_before_stressed_dm', 24: 'pitch_slope_after_stressed_dm', 25: 'ratio_max_intensity_dm', 26: 'ratio_min_intensity_dm', 27: 'ratio_max_intensity_stressed_dm', 28: 'ratio_min_intensity_stressed_dm', 29: 'ratio_max_f0_dm', 30: 'ratio_min_f0_dm', 31: 'ratio_max_f0_stressed_dm', 32: 'ratio_min_f0_stressed_dm', 33: 'zsil_mean', 34: 'zsil_stressed_syl', 35: 'dm_duration', 36: 'coef_0', 37: 'coef_1', 38: 'coef_2', 39: 'coef_3', 40: 'dm_text_encoded', 41: 'iu_encoded'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that encodes column names and their indexes\n",
    "col_names = dict(enumerate(data.columns))\n",
    "\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try a first model with all the variables + postion. We do include the dm_text_encoded variable\n",
    "# We will create a list with the indices of the variables that will be used in the model: 4 + 9 to 33\n",
    "variables_01 = [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39]\n",
    "\n",
    "# We get the data for the model and store it in X\n",
    "X = data.iloc[:, variables_01].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  68]\n",
      " [  1 139]\n",
      " [  2  75]\n",
      " [  3  69]\n",
      " [  4  80]]\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in the target variable\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If check if there are missing values and replace them with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# We fit the imputer to the data\n",
    "imputer.fit(X)\n",
    "\n",
    "# We transform the data\n",
    "X_imputed = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  3  2  0  0]\n",
      " [ 2 22  4  2  5]\n",
      " [ 0  1 16  1  1]\n",
      " [ 0  0  1 13  3]\n",
      " [ 0  2  0  5 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77        17\n",
      "           1       0.79      0.63      0.70        35\n",
      "           2       0.70      0.84      0.76        19\n",
      "           3       0.62      0.76      0.68        17\n",
      "           4       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.70       108\n",
      "   macro avg       0.71      0.72      0.71       108\n",
      "weighted avg       0.72      0.70      0.70       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We build a base LDA model\n",
    "lda_model = LDA()\n",
    "\n",
    "# We fit the model\n",
    "lda_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred = lda_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  3  3  1  0]\n",
      " [ 4 23  2  3  3]\n",
      " [ 1  2 13  2  1]\n",
      " [ 0  1  2 11  3]\n",
      " [ 0  4  0  6 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62        17\n",
      "           1       0.70      0.66      0.68        35\n",
      "           2       0.65      0.68      0.67        19\n",
      "           3       0.48      0.65      0.55        17\n",
      "           4       0.59      0.50      0.54        20\n",
      "\n",
      "    accuracy                           0.62       108\n",
      "   macro avg       0.62      0.62      0.61       108\n",
      "weighted avg       0.63      0.62      0.62       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We do a KNN model\n",
    "knn_model = KNN(n_neighbors=6)\n",
    "\n",
    "# We fit the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  8  4  0  0]\n",
      " [ 4 16  2  3 10]\n",
      " [ 0  4 15  0  0]\n",
      " [ 0  2  1 12  2]\n",
      " [ 0  1  0  9 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38        17\n",
      "           1       0.52      0.46      0.48        35\n",
      "           2       0.68      0.79      0.73        19\n",
      "           3       0.50      0.71      0.59        17\n",
      "           4       0.45      0.50      0.48        20\n",
      "\n",
      "    accuracy                           0.54       108\n",
      "   macro avg       0.54      0.55      0.53       108\n",
      "weighted avg       0.54      0.54      0.53       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We do a Naive Bayes model\n",
    "nb_model = NaiveBayes()\n",
    "\n",
    "# We fit the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  4  3  0  0]\n",
      " [ 2 29  0  2  2]\n",
      " [ 0  3 15  0  1]\n",
      " [ 0  2  2  9  4]\n",
      " [ 0  5  0  8  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.67      0.83      0.74        35\n",
      "           2       0.75      0.79      0.77        19\n",
      "           3       0.47      0.53      0.50        17\n",
      "           4       0.50      0.35      0.41        20\n",
      "\n",
      "    accuracy                           0.65       108\n",
      "   macro avg       0.65      0.62      0.62       108\n",
      "weighted avg       0.65      0.65      0.64       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do a random forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3315            1.09m\n",
      "         2           1.1697            1.11m\n",
      "         3           1.0426           55.67s\n",
      "         4           0.9359           51.03s\n",
      "         5           0.8477           46.70s\n",
      "         6           0.7755           43.29s\n",
      "         7           0.7094           39.76s\n",
      "         8           0.6530           37.21s\n",
      "         9           0.6044           35.46s\n",
      "        10           0.5606           33.94s\n",
      "        20           0.2861           27.60s\n",
      "        30           0.1711           27.96s\n",
      "        40           0.1117           28.24s\n",
      "        50           0.0751           28.27s\n",
      "        60           0.0511           26.98s\n",
      "        70           0.0348           25.57s\n",
      "        80           0.0250           24.85s\n",
      "        90           0.0177           23.84s\n",
      "       100           0.0127           23.74s\n",
      "       200           0.0006           20.24s\n",
      "       300           0.0000           17.06s\n",
      "       400           0.0000           13.84s\n",
      "       500           0.0000           11.07s\n",
      "       600           0.0000            8.13s\n",
      "       700           0.0000            5.38s\n",
      "       800           0.0000            3.23s\n",
      "       900           0.0000            1.47s\n",
      "      1000           0.0000            0.00s\n",
      "[[12  2  3  0  0]\n",
      " [ 1 29  0  2  3]\n",
      " [ 0  3 13  1  2]\n",
      " [ 0  3  2 10  2]\n",
      " [ 0  5  0  7  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80        17\n",
      "           1       0.69      0.83      0.75        35\n",
      "           2       0.72      0.68      0.70        19\n",
      "           3       0.50      0.59      0.54        17\n",
      "           4       0.53      0.40      0.46        20\n",
      "\n",
      "    accuracy                           0.67       108\n",
      "   macro avg       0.67      0.64      0.65       108\n",
      "weighted avg       0.67      0.67      0.66       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do a gradient boosting model, we want to use a verbose to see the progress of the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=1000, random_state=21, verbose=1)\n",
    "\n",
    "# We fit the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  4  3  0  0]\n",
      " [ 1 29  1  2  2]\n",
      " [ 0  1 17  0  1]\n",
      " [ 0  1  0 14  2]\n",
      " [ 0  4  0  7  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.74      0.83      0.78        35\n",
      "           2       0.81      0.89      0.85        19\n",
      "           3       0.61      0.82      0.70        17\n",
      "           4       0.64      0.45      0.53        20\n",
      "\n",
      "    accuracy                           0.73       108\n",
      "   macro avg       0.74      0.72      0.72       108\n",
      "weighted avg       0.74      0.73      0.72       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We want to try a bagging model\n",
    "bag_model = Bagging(n_estimators=1000, random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "bag_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_bag = bag_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_bag))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 10  7  0  0]\n",
      " [ 0 28  1  3  3]\n",
      " [ 0  1 18  0  0]\n",
      " [ 0  1  1 15  0]\n",
      " [ 0  4  0 14  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.64      0.80      0.71        35\n",
      "           2       0.67      0.95      0.78        19\n",
      "           3       0.47      0.88      0.61        17\n",
      "           4       0.40      0.10      0.16        20\n",
      "\n",
      "    accuracy                           0.58       108\n",
      "   macro avg       0.43      0.55      0.45       108\n",
      "weighted avg       0.47      0.58      0.49       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# We want to try an AdaBoost model\n",
    "ada_model = AdaBoost(n_estimators=1000, random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  3  3  0  0]\n",
      " [ 2 23  2  1  7]\n",
      " [ 3  1 14  0  1]\n",
      " [ 1  0  0 13  3]\n",
      " [ 0  4  0  7  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65        17\n",
      "           1       0.74      0.66      0.70        35\n",
      "           2       0.74      0.74      0.74        19\n",
      "           3       0.62      0.76      0.68        17\n",
      "           4       0.45      0.45      0.45        20\n",
      "\n",
      "    accuracy                           0.65       108\n",
      "   macro avg       0.64      0.65      0.64       108\n",
      "weighted avg       0.65      0.65      0.65       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We want to try a decision tree model\n",
    "dt_model = DecisionTree(random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  5  4  1  0]\n",
      " [ 1 27  2  1  4]\n",
      " [ 0  2 12  1  4]\n",
      " [ 0  2  2  8  5]\n",
      " [ 0  4  0  6 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.41      0.56        17\n",
      "           1       0.68      0.77      0.72        35\n",
      "           2       0.60      0.63      0.62        19\n",
      "           3       0.47      0.47      0.47        17\n",
      "           4       0.43      0.50      0.47        20\n",
      "\n",
      "    accuracy                           0.59       108\n",
      "   macro avg       0.61      0.56      0.57       108\n",
      "weighted avg       0.62      0.59      0.59       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We want to try a SVM model\n",
    "svm_model = SVC(random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  8  1  0  0]\n",
      " [ 6 16  1  0 12]\n",
      " [ 0  5 14  0  0]\n",
      " [ 2  5  0  8  2]\n",
      " [ 0  4  0  5 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48        17\n",
      "           1       0.42      0.46      0.44        35\n",
      "           2       0.88      0.74      0.80        19\n",
      "           3       0.62      0.47      0.53        17\n",
      "           4       0.44      0.55      0.49        20\n",
      "\n",
      "    accuracy                           0.53       108\n",
      "   macro avg       0.57      0.54      0.55       108\n",
      "weighted avg       0.55      0.53      0.53       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# We want to try a QDA model\n",
    "qda_model = QDA()\n",
    "\n",
    "# We fit the model\n",
    "qda_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_qda = qda_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_qda))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_qda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  4  3  0  0]\n",
      " [ 1 26  2  3  3]\n",
      " [ 0  2 14  0  3]\n",
      " [ 1  1  1  9  5]\n",
      " [ 0  2  0  6 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.74      0.74      0.74        35\n",
      "           2       0.70      0.74      0.72        19\n",
      "           3       0.50      0.53      0.51        17\n",
      "           4       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.66       108\n",
      "   macro avg       0.66      0.64      0.64       108\n",
      "weighted avg       0.67      0.66      0.66       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# We want to try a logistic regression model\n",
    "lr_model = LogisticRegression(random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  5  3  0  0]\n",
      " [ 1 26  0  3  5]\n",
      " [ 0  1 16  0  2]\n",
      " [ 0  2  2  9  4]\n",
      " [ 0  2  0  6 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.53      0.67        17\n",
      "           1       0.72      0.74      0.73        35\n",
      "           2       0.76      0.84      0.80        19\n",
      "           3       0.50      0.53      0.51        17\n",
      "           4       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.67       108\n",
      "   macro avg       0.68      0.65      0.65       108\n",
      "weighted avg       0.69      0.67      0.67       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Lets do an MLP Classifier model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 10  4  0  0]\n",
      " [ 3 25  0  2  5]\n",
      " [ 2  2 14  0  1]\n",
      " [ 0  3  1 11  2]\n",
      " [ 2  3  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.18      0.22        17\n",
      "           1       0.58      0.71      0.64        35\n",
      "           2       0.74      0.74      0.74        19\n",
      "           3       0.85      0.65      0.73        17\n",
      "           4       0.65      0.75      0.70        20\n",
      "\n",
      "    accuracy                           0.63       108\n",
      "   macro avg       0.62      0.60      0.61       108\n",
      "weighted avg       0.62      0.63      0.62       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets try a Passive Aggressive Classifier model\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pa_model = PassiveAggressiveClassifier(random_state=21)\n",
    "\n",
    "# We fit the model\n",
    "pa_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_pa = pa_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_pa))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3325           18.57s\n",
      "         2           1.1726           18.06s\n",
      "         3           1.0464           17.49s\n",
      "         4           0.9462           17.07s\n",
      "         5           0.8568           17.82s\n",
      "         6           0.7849           18.21s\n",
      "         7           0.7162           18.95s\n",
      "         8           0.6585           19.56s\n",
      "         9           0.6082           19.80s\n",
      "        10           0.5653           20.64s\n",
      "        20           0.2985           21.92s\n",
      "        30           0.1835           20.55s\n",
      "        40           0.1219           19.78s\n",
      "        50           0.0820           19.00s\n",
      "        60           0.0587           18.66s\n",
      "        70           0.0426           18.07s\n",
      "        80           0.0300           17.81s\n",
      "        90           0.0215           17.35s\n",
      "       100           0.0158           17.10s\n",
      "       200           0.0007           14.52s\n",
      "       300           0.0000           12.79s\n",
      "       400           0.0000           10.82s\n",
      "       500           0.0000            8.88s\n",
      "       600           0.0000            6.78s\n",
      "       700           0.0000            4.53s\n",
      "       800           0.0000            2.73s\n",
      "       900           0.0000            1.25s\n",
      "      1000           0.0000            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4  5  0  0]\n",
      " [ 2 29  0  2  2]\n",
      " [ 0  2 17  0  0]\n",
      " [ 0  2  2 11  2]\n",
      " [ 0  6  0  6  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.47      0.59        17\n",
      "           1       0.67      0.83      0.74        35\n",
      "           2       0.71      0.89      0.79        19\n",
      "           3       0.58      0.65      0.61        17\n",
      "           4       0.67      0.40      0.50        20\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.69      0.65      0.65       108\n",
      "weighted avg       0.68      0.68      0.66       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "# Lets try a Voting Classifier model with the best models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# We create a list with the models\n",
    "estimators = [('rf', rf_model), ('gb', gb_model), ('bag', bag_model), ('ada', ada_model), ('dt', dt_model), ('svm', svm_model), ('qda', qda_model), ('lr', lr_model), ('mlp', mlp_model), ('pa', pa_model)]\n",
    "\n",
    "# We create the voting classifier\n",
    "voting_model = VotingClassifier(estimators=estimators, voting='hard')\n",
    "\n",
    "# We fit the model\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the test set\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# We print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_voting))\n",
    "\n",
    "# We print the classification report\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "#TODO: We should no get all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 8\n",
      "Selected Features: [ True False False False False  True False  True False False False False\n",
      " False False False False  True False False False  True False False False\n",
      " False  True  True  True False]\n",
      "Feature Ranking: [ 1  9  6 10 12  1  3  1  5  4 11 19 20 16 21 22  1  8 17 14  1  2 13 18\n",
      " 15  1  1  1  7]\n",
      "Feature Names: Index(['position', 'mean_pitch_dm', 'std_pitch_dm', 'max_pitch_dm',\n",
      "       'min_pitch_dm', 'mean_intensity_dm', 'std_intensity_dm',\n",
      "       'max_intensity_dm', 'min_intensity_dm', 'mean_intensity_stressed_dm',\n",
      "       'mean_se_stressed_dm', 'pitch_slope_dm', 'pitch_slope_stressed_dm',\n",
      "       'pitch_range_dm', 'pitch_slope_before_stressed_dm',\n",
      "       'pitch_slope_after_stressed_dm', 'ratio_max_intensity_dm',\n",
      "       'ratio_min_intensity_dm', 'ratio_max_intensity_stressed_dm',\n",
      "       'ratio_min_intensity_stressed_dm', 'ratio_max_f0_dm', 'ratio_min_f0_dm',\n",
      "       'ratio_max_f0_stressed_dm', 'ratio_min_f0_stressed_dm',\n",
      "       'zsil_stressed_syl', 'coef_0', 'coef_1', 'coef_2', 'coef_3'],\n",
      "      dtype='object')\n",
      "Index(['position', 'mean_intensity_dm', 'max_intensity_dm',\n",
      "       'ratio_max_intensity_dm', 'ratio_max_f0_dm', 'coef_0', 'coef_1',\n",
      "       'coef_2'],\n",
      "      dtype='object')\n",
      "Index(['mean_pitch_dm', 'mean_intensity_stressed_dm', 'std_intensity_dm',\n",
      "       'mean_se_stressed_dm', 'pitch_slope_stressed_dm', 'mean_pitch_dm',\n",
      "       'max_pitch_dm', 'mean_pitch_dm', 'mean_intensity_dm', 'min_pitch_dm',\n",
      "       'pitch_slope_dm', 'ratio_min_intensity_stressed_dm', 'ratio_max_f0_dm',\n",
      "       'ratio_max_intensity_dm', 'ratio_min_f0_dm', 'ratio_max_f0_stressed_dm',\n",
      "       'mean_pitch_dm', 'min_intensity_dm', 'ratio_min_intensity_dm',\n",
      "       'pitch_slope_before_stressed_dm', 'mean_pitch_dm', 'std_pitch_dm',\n",
      "       'pitch_range_dm', 'ratio_max_intensity_stressed_dm',\n",
      "       'pitch_slope_after_stressed_dm', 'mean_pitch_dm', 'mean_pitch_dm',\n",
      "       'mean_pitch_dm', 'max_intensity_dm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We should now try some method to choose the best features for the model. A feature selection method\n",
    "# We will use the Recursive Feature Elimination method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# We will use the LDAModel as the estimator\n",
    "\n",
    "# We create the RFE model and select 8 attributes\n",
    "rfe_model = RFE(lda_model, n_features_to_select=8)\n",
    "\n",
    "# We fit the model\n",
    "rfe_model.fit(X_train, y_train)\n",
    "\n",
    "# We print the results\n",
    "print(\"Num Features: %d\" % rfe_model.n_features_)\n",
    "print(\"Selected Features: %s\" % rfe_model.support_)\n",
    "print(\"Feature Ranking: %s\" % rfe_model.ranking_)\n",
    "print(\"Feature Names: %s\" % data.columns[variables_01])\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(data.columns[variables_01][rfe_model.support_])\n",
    "\n",
    "# Print the names of all features as ranked by the RFE\n",
    "print(data.columns[variables_01][rfe_model.ranking_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 451, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py\", line 752, in decision_function\n",
      "    return super().decision_function(X)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 432, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/base.py\", line 604, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "/home/saulo/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py\", line 581, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/saulo/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try select k best\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target variable\n",
    "# X, y = ...\n",
    "\n",
    "# Step 1: Feature scaling (if needed)\n",
    "\n",
    "# Step 2: Initial LDA model\n",
    "lda_02 = LinearDiscriminantAnalysis()\n",
    "initial_accuracy = np.mean(cross_val_score(lda_02, X, y, cv=5, scoring='accuracy'))\n",
    "\n",
    "# Step 3: Feature selection\n",
    "feature_range = range(1, X.shape[1] + 1)\n",
    "accuracies = []\n",
    "\n",
    "for num_features in feature_range:\n",
    "    # Select top k features using ANOVA F-value\n",
    "    selector = SelectKBest(f_classif, k=num_features)\n",
    "    X_selected = selector.fit_transform(X_imputed, y)\n",
    "\n",
    "    # Step 4: Train LDA model\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    accuracy = np.mean(cross_val_score(lda, X_selected, y, cv=5, scoring='accuracy'))\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Step 5: Plotting\n",
    "plt.plot(feature_range, accuracies, marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Number of Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAGGING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your data loaded in X_imputed and y\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base classifiers and their parameter grids for tuning\n",
    "base_classifiers = {\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LDA__n_components': [1, 2, 3, 4],\n",
    "    'DecisionTree__base_estimator__max_depth': [None, 5, 10, 15],\n",
    "    'DecisionTree__base_estimator__min_samples_split': [2, 5, 10],\n",
    "    'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "    'KNN__p': [1, 2]\n",
    "}\n",
    "\n",
    "# Lists to store results\n",
    "accuracy_scores = []\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for base_classifier_name, base_classifier in base_classifiers.items():\n",
    "    # Create a pipeline for each base classifier\n",
    "    pipeline = Pipeline([\n",
    "        (base_classifier_name, base_classifier),\n",
    "        ('bagging', BaggingClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    param_grid = param_grids.copy()\n",
    "    param_grid.update({f'{base_classifier_name}__{key}': value for key, value in param_grids.items()})\n",
    "\n",
    "    # GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring='accuracy', verbose=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best classifier from the grid search\n",
    "    best_bagging_classifier = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = best_bagging_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the results\n",
    "    accuracy_scores.append((base_classifier_name, grid_search.best_params_, accuracy))\n",
    "\n",
    "# Print the results\n",
    "for result in accuracy_scores:\n",
    "    print(f\"{result[0]} - Best Parameters: {result[1]}, Test Accuracy: {result[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
