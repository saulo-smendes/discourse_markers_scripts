{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python3 -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installation done!\n"
     ]
    }
   ],
   "source": [
    "#### Check for libraries and updates ####\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "required = {\"tensorflow\", \"scikit-learn\", \"h5py\", \"numpy\", \"pandas\", \"scipy\", \"keras\", \"scikeras[tensorflow]\"}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "print(\"Package installation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 15:34:05.030488: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 15:34:05.123896: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 15:34:05.124553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 15:34:07.952712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "#### Import libraries ####\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import scipy\n",
    "from datetime import datetime\n",
    "#import librosa\n",
    "#import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, GRU, MaxPooling2D, Conv2D, Flatten, Dropout, BatchNormalization, Activation, MaxPooling1D, Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling2D, GlobalMaxPooling1D\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import merged data from C:\\Users\\Saulo Mendes Santos\\OneDrive\\Documents\\2. LETRAS\\0. Doutorado\\0. Recherche\\2.2. Voicing Decision Modelling\\VD_model_03-context\\RNN_2D-vector\\20230130_Bidirectional-RNN_server-malbec\n",
    "\n",
    "#file_path = \"C:/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/2.2. Voicing Decision Modelling/VD_model_03-context/RNN_2D-vector/20230130_Bidirectional-RNN_server-malbec/merged_CSTR-KEELE_file.hdf5\"\n",
    "\n",
    "# Import data h5py file\n",
    "file_path = '/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.1. F0 final/TODOS_resampled_5ms_20231115.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to stack data\n",
    "# We change the function to customize the number of folds\n",
    "# In this specific case, we want to have just one fold for training and evaluation\n",
    "# We also use the shuffle parameter to shuffle the data before splitting it into folds\n",
    "def stack_split_data(f, validation_split=0.25):\n",
    "    \"\"\"\n",
    "    Stack and fold the data from the h5py file.\n",
    "    f: h5py file\n",
    "\n",
    "    \"\"\"\n",
    "    # we want to pad the last 7 rows with zeros\n",
    "    pad_width = ((3, 4), (0, 0))\n",
    "    # the constant mode will use the edge values to fill the padded regions with zeros as default\n",
    "    mode = 'constant'\n",
    "\n",
    "    # Get the list of groups in the h5py file\n",
    "    groups = list(f.keys())\n",
    "\n",
    "    # Filter out the groups containing \"_egg\" and groups that do not contain \"_\" from the groups list\n",
    "    groups = [group for group in groups if \"_egg\" not in group and \"_\" in group]\n",
    "\n",
    "    # Create a dictionary to associate the index of the group as a key to the group name as the value\n",
    "    group_dict = {i: group for i, group in enumerate(groups)}\n",
    "\n",
    "    # Attention: instead of using KFold, we will build an array with the indices of the groups and randomly pick items for training and validation sets\n",
    "    # This is necessary because KFold does not allow to have a group with only one fold: n_splits must be at least 2\n",
    "    # We will use the same random state to make sure that the same groups are picked for training and validation\n",
    "    ids_array = np.arange(len(groups))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(ids_array)\n",
    "    training_ratio = 1 - validation_split\n",
    "    train_ids = ids_array[:int(len(ids_array) * training_ratio)]\n",
    "    valid_ids = ids_array[int(len(ids_array) * training_ratio):]\n",
    "    train_arrays, valid_arrays = [], []\n",
    "\n",
    "    # Now we iterate over the groups and stack the data\n",
    "    for train_i in train_ids:\n",
    "        group_name = group_dict[train_i]\n",
    "        # Get the dataset in group\n",
    "        data = np.array(f[group_name])\n",
    "        # But we need to pad the edges of the 0-th axis with the same values of the first and last lines\n",
    "        padded_data = np.pad(data, pad_width=pad_width, mode=mode)\n",
    "        # Add the id of the group as a column of the data\n",
    "        padded_data = np.hstack((padded_data, np.ones((padded_data.shape[0], 1)) * train_i))\n",
    "        # Append the padded data to the list\n",
    "        train_arrays.append(padded_data)\n",
    "    \n",
    "    if validation_split != 1:\n",
    "        train_data = np.vstack(train_arrays)\n",
    "    else:\n",
    "        train_data = np.nan\n",
    "    \n",
    "    # Now we do the same but for the validation data\n",
    "    for valid_i in valid_ids:\n",
    "        group_name = group_dict[valid_i]\n",
    "        data = np.array(f[group_name])\n",
    "        padded_data = np.pad(data, pad_width=pad_width, mode=mode)\n",
    "        padded_data = np.hstack((padded_data, np.ones((padded_data.shape[0], 1)) * valid_i))\n",
    "        valid_arrays.append(padded_data)\n",
    "\n",
    "    if validation_split != 0:\n",
    "        valid_data = np.vstack(valid_arrays)\n",
    "    else:\n",
    "        valid_data = np.nan\n",
    "\n",
    "    return train_data, valid_data, group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(file_path, 'r')\n",
    "train_data, test_data, group_dict = stack_split_data(f, validation_split=1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319223, 41)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "#print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16919615864753723"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check last MFCC data\n",
    "test_data[-10, 39]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to calculate Voicing Decision Error rates only of test data, we should have enough files for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([265., 265., 265., ..., 102., 102., 102.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have the index of the file in the last column\n",
    "test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'bfamcv01__002__GIL'),\n",
       " (1, 'bfamcv01__019__EVN'),\n",
       " (2, 'bfamcv01__048__EVN'),\n",
       " (3, 'bfamcv01__051__LUI'),\n",
       " (4, 'bfamcv01__054__EVN'),\n",
       " (5, 'bfamcv01__062__GIL'),\n",
       " (6, 'bfamcv01__068__GIL'),\n",
       " (7, 'bfamcv01__127__LEO'),\n",
       " (8, 'bfamcv01__141__EVN'),\n",
       " (9, 'bfamcv01__142__GIL')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 keys and values of the group_dict\n",
    "list(group_dict.items())[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model layers\n",
    "# Define and wrap the model\n",
    "# import KerasClassifier from keras wrappers\n",
    "# Define the function that creates the model\n",
    "def create_model(input_shape=(7, 38, 1)):\n",
    "    # create model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    cnn = Sequential()\n",
    "    # convolutional layer with rectified linear unit activation\n",
    "    cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                    activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    # 32 convolution filters used each of size 3x3\n",
    "    # again\n",
    "    cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    # 64 convolution filters used each of size 3x3\n",
    "    # choose the best features via pooling\n",
    "    cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # randomly turn neurons on and off to improve convergence\n",
    "    # TODO: double the dropout rate to 0.5 during the hyperparameter tuning\n",
    "    cnn.add(Dropout(0.25))\n",
    "    # flatten since too many dimensions, we only want a classification output\n",
    "    cnn.add(Flatten())\n",
    "    # fully connected to get all relevant data\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "    # one more dropout for convergence' sake :) \n",
    "    cnn.add(Dropout(0.5))\n",
    "    # output a softmax to squash the matrix into output probabilities\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    # TODO: change the metrics to recall and precision: f1-score.\n",
    "    cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sliding window generator\n",
    "class SlidingWindowDataGenerator(Sequence):\n",
    "    def __init__(self, x, y, window_size, batch_size, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        # Problem: the last window\n",
    "        #self.indices = np.arange(len(self.x))\n",
    "        self.indices = np.arange(len(self.x)-(self.window_size[0]))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # O problema est√° aqui\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # print(\"batch_indices: \", batch_indices)\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for i in batch_indices:\n",
    "            # x shape: (5639045, 38)\n",
    "            # window_size = (7, 38, 1)\n",
    "            window = self.x[i:i+self.window_size[0],:].reshape(*self.window_size)\n",
    "            # We need to the label \n",
    "            label = self.y[i + (self.window_size[0]//2)]\n",
    "            batch_x.append(window)\n",
    "            batch_y.append(label)\n",
    "        batch_x = np.array(batch_x)\n",
    "        # Reshape the batch to train a CNN\n",
    "        # batch_x = batch_x.reshape(batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], 1)\n",
    "        # batch_y = to_categorical(np.array(batch_y, dtype=int), num_classes=np.max(self.y)+1)\n",
    "        # Convert the list to an array of integers\n",
    "        # batch_y = to_categorical([int(x) for x in batch_y])\n",
    "        batch_y = np.array(batch_y, dtype=int)\n",
    "\n",
    "        # print sizes\n",
    "        # print('batch_x shape: {}'.format(batch_x.shape))\n",
    "        # print('batch_y shape: {}'.format(batch_y.shape))\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            # Random state is set to 42 to ensure reproducibility\n",
    "            np.random.seed(42)\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDataGeneratorPrediction(Sequence):\n",
    "    def __init__(self, x, window_size, batch_size):\n",
    "        self.x = x\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.x) - (self.window_size[0]))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        batch_x = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            window = self.x[i: i + self.window_size[0], :].reshape(*self.window_size)\n",
    "            batch_x.append(window)\n",
    "\n",
    "        batch_x = np.array(batch_x)\n",
    "\n",
    "        return batch_x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # No shuffling for prediction\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will have 3 models:\n",
    "- One only with MFCCs\n",
    "- One only with f0 estimations\n",
    "- One with all the features\n",
    "\n",
    "We will have the predictions made by these models stacked to the data matrix, which should finally be save into an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nContenu des colonnes :\\n0   :   ground_truth\\n1   :   voiced_ground_truth\\n2   :   bana_resampled\\n3   :   opensmile_resampled\\n4   :   pefac_resampled\\n5   :   praat_ac_resampled\\n6   :   praat_cc_resampled\\n7   :   praat_shs_resampled\\n8   :   pyin_resampled\\n9   :   rapt_resampled\\n10  :   srh_resampled\\n11  :   straight_resampled\\n12  :   swipe_resampled\\n13  :   swipep_resampled\\n14  :   yaapt_resampled\\n15  :   yin_resampled\\n16  :   hnr_resampled\\n17  :   cpps_resampled\\n18  :   praat_intensity_resampled\\n19  :   praat_se_resampled\\n20  :   mfcc_01\\n21  :   mfcc_02\\n22  :   mfcc_03\\n23  :   mfcc_04\\n24  :   mfcc_05\\n25  :   mfcc_06\\n26  :   mfcc_07\\n27  :   mfcc_08\\n28  :   mfcc_09\\n29  :   mfcc_10\\n30  :   mfcc_11\\n31  :   mfcc_12\\n32  :   mfcc_13\\n33  :   mfcc_14\\n34  :   mfcc_15\\n35  :   mfcc_16\\n36  :   mfcc_17\\n37  :   mfcc_18\\n38  :   mfcc_19\\n39  :   mfcc_20\\n40  :   group_index / file_index\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Contenu des colonnes :\n",
    "0   :   timeframes (not used for the model)\n",
    "1   :   creacky_voice decision (0 = no creacky voice, 1 = creacky voice) Not used for the model\n",
    "2   :   bana_resampled\n",
    "3   :   opensmile_resampled\n",
    "4   :   pefac_resampled\n",
    "5   :   praat_ac_resampled\n",
    "6   :   praat_cc_resampled\n",
    "7   :   praat_shs_resampled\n",
    "8   :   pyin_resampled\n",
    "9   :   rapt_resampled\n",
    "10  :   srh_resampled\n",
    "11  :   straight_resampled\n",
    "12  :   swipe_resampled\n",
    "13  :   swipep_resampled\n",
    "14  :   yaapt_resampled\n",
    "15  :   yin_resampled\n",
    "16  :   hnr_resampled\n",
    "17  :   cpps_resampled\n",
    "18  :   praat_intensity_resampled\n",
    "19  :   praat_se_resampled\n",
    "20  :   mfcc_01\n",
    "21  :   mfcc_02\n",
    "22  :   mfcc_03\n",
    "23  :   mfcc_04\n",
    "24  :   mfcc_05\n",
    "25  :   mfcc_06\n",
    "26  :   mfcc_07\n",
    "27  :   mfcc_08\n",
    "28  :   mfcc_09\n",
    "29  :   mfcc_10\n",
    "30  :   mfcc_11\n",
    "31  :   mfcc_12\n",
    "32  :   mfcc_13\n",
    "33  :   mfcc_14\n",
    "34  :   mfcc_15\n",
    "35  :   mfcc_16\n",
    "36  :   mfcc_17\n",
    "37  :   mfcc_18\n",
    "38  :   mfcc_19\n",
    "39  :   mfcc_20\n",
    "40  :   group_index / file_index (Not used for the model)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows sizes for the different models\n",
    "window_size_all = (7, 38, 1)\n",
    "window_size_mfcc = (7, 20, 1)\n",
    "window_size_f0 = (7, 18, 1)\n",
    "window_size_list = [window_size_all, window_size_mfcc, window_size_f0]\n",
    "\n",
    "# We initialize the models and the indices that will be used to train and test the models\n",
    "cnn_all = create_model(input_shape=window_size_all)\n",
    "cnn_mfcc = create_model(input_shape=window_size_mfcc)\n",
    "cnn_f0 = create_model(input_shape=window_size_f0)\n",
    "models = [cnn_all, cnn_mfcc, cnn_f0]\n",
    "\n",
    "# Indices for the different models\n",
    "indices_all = (2, 40)\n",
    "indices_mfcc = (20, 40)\n",
    "indices_f0 = (2, 20)\n",
    "indices_list = [indices_all, indices_mfcc, indices_f0]\n",
    "\n",
    "\n",
    "# Iterate over the folds and train/test sets\n",
    "histories = []\n",
    "model_names = ['cnn_all', 'cnn_mfcc', 'cnn_f0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  cnn_all\n",
      "Epoch 1/10\n",
      "16313/16313 [==============================] - 1922s 118ms/step - loss: 0.3448 - accuracy: 0.8433 - val_loss: 0.3067 - val_accuracy: 0.8574\n",
      "Epoch 2/10\n",
      "16313/16313 [==============================] - 1696s 104ms/step - loss: 0.3136 - accuracy: 0.8549 - val_loss: 0.2949 - val_accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "16313/16313 [==============================] - 1610s 99ms/step - loss: 0.3056 - accuracy: 0.8585 - val_loss: 0.2884 - val_accuracy: 0.8653\n",
      "Epoch 4/10\n",
      "16313/16313 [==============================] - 1566s 96ms/step - loss: 0.3010 - accuracy: 0.8606 - val_loss: 0.2837 - val_accuracy: 0.8665\n",
      "Epoch 5/10\n",
      "16313/16313 [==============================] - 1547s 95ms/step - loss: 0.2978 - accuracy: 0.8619 - val_loss: 0.2810 - val_accuracy: 0.8690\n",
      "Epoch 6/10\n",
      "16313/16313 [==============================] - 1594s 98ms/step - loss: 0.2953 - accuracy: 0.8631 - val_loss: 0.2767 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "16313/16313 [==============================] - 1572s 96ms/step - loss: 0.2935 - accuracy: 0.8639 - val_loss: 0.2728 - val_accuracy: 0.8721\n",
      "Epoch 8/10\n",
      "16313/16313 [==============================] - 1630s 100ms/step - loss: 0.2920 - accuracy: 0.8646 - val_loss: 0.2724 - val_accuracy: 0.8723\n",
      "Epoch 9/10\n",
      "16313/16313 [==============================] - 1561s 96ms/step - loss: 0.2908 - accuracy: 0.8649 - val_loss: 0.2722 - val_accuracy: 0.8730\n",
      "Epoch 10/10\n",
      "16313/16313 [==============================] - 1551s 95ms/step - loss: 0.2895 - accuracy: 0.8654 - val_loss: 0.2718 - val_accuracy: 0.8726\n",
      "5358/5358 [==============================] - 132s 25ms/step\n",
      "Training model:  cnn_mfcc\n",
      "Epoch 1/10\n",
      "16313/16313 [==============================] - 873s 53ms/step - loss: 0.3991 - accuracy: 0.8083 - val_loss: 0.3431 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "16313/16313 [==============================] - 858s 53ms/step - loss: 0.3623 - accuracy: 0.8280 - val_loss: 0.3256 - val_accuracy: 0.8469\n",
      "Epoch 3/10\n",
      "16313/16313 [==============================] - 846s 52ms/step - loss: 0.3530 - accuracy: 0.8326 - val_loss: 0.3206 - val_accuracy: 0.8526\n",
      "Epoch 4/10\n",
      "16313/16313 [==============================] - 886s 54ms/step - loss: 0.3475 - accuracy: 0.8354 - val_loss: 0.3159 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "16313/16313 [==============================] - 860s 53ms/step - loss: 0.3441 - accuracy: 0.8370 - val_loss: 0.3147 - val_accuracy: 0.8543\n",
      "Epoch 6/10\n",
      "16313/16313 [==============================] - 876s 54ms/step - loss: 0.3416 - accuracy: 0.8383 - val_loss: 0.3086 - val_accuracy: 0.8569\n",
      "Epoch 7/10\n",
      "16313/16313 [==============================] - 865s 53ms/step - loss: 0.3394 - accuracy: 0.8392 - val_loss: 0.3062 - val_accuracy: 0.8595\n",
      "Epoch 8/10\n",
      "16313/16313 [==============================] - 900s 55ms/step - loss: 0.3380 - accuracy: 0.8398 - val_loss: 0.3001 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "16313/16313 [==============================] - 873s 54ms/step - loss: 0.3366 - accuracy: 0.8403 - val_loss: 0.3019 - val_accuracy: 0.8617\n",
      "Epoch 10/10\n",
      "16313/16313 [==============================] - 908s 56ms/step - loss: 0.3356 - accuracy: 0.8409 - val_loss: 0.3013 - val_accuracy: 0.8610\n",
      "5358/5358 [==============================] - 77s 14ms/step\n",
      "Training model:  cnn_f0\n",
      "Epoch 1/10\n",
      "16313/16313 [==============================] - 786s 48ms/step - loss: 0.3871 - accuracy: 0.8290 - val_loss: 0.3573 - val_accuracy: 0.8345\n",
      "Epoch 2/10\n",
      "16313/16313 [==============================] - 819s 50ms/step - loss: 0.3572 - accuracy: 0.8371 - val_loss: 0.3482 - val_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "16313/16313 [==============================] - 785s 48ms/step - loss: 0.3500 - accuracy: 0.8394 - val_loss: 0.3436 - val_accuracy: 0.8385\n",
      "Epoch 4/10\n",
      "16313/16313 [==============================] - 804s 49ms/step - loss: 0.3462 - accuracy: 0.8405 - val_loss: 0.3406 - val_accuracy: 0.8409\n",
      "Epoch 5/10\n",
      "16313/16313 [==============================] - 792s 49ms/step - loss: 0.3439 - accuracy: 0.8414 - val_loss: 0.3458 - val_accuracy: 0.8381\n",
      "Epoch 6/10\n",
      "16313/16313 [==============================] - 805s 49ms/step - loss: 0.3423 - accuracy: 0.8417 - val_loss: 0.3394 - val_accuracy: 0.8399\n",
      "Epoch 7/10\n",
      "16313/16313 [==============================] - 805s 49ms/step - loss: 0.3415 - accuracy: 0.8421 - val_loss: 0.3362 - val_accuracy: 0.8419\n",
      "Epoch 8/10\n",
      "16313/16313 [==============================] - 797s 49ms/step - loss: 0.3406 - accuracy: 0.8421 - val_loss: 0.3360 - val_accuracy: 0.8408\n",
      "Epoch 9/10\n",
      "16313/16313 [==============================] - 793s 49ms/step - loss: 0.3400 - accuracy: 0.8426 - val_loss: 0.3335 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "16313/16313 [==============================] - 835s 51ms/step - loss: 0.3395 - accuracy: 0.8427 - val_loss: 0.3395 - val_accuracy: 0.8411\n",
      "5358/5358 [==============================] - 70s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# This part is not used since we are predicting new values stored in the test_data array\n",
    "\"\"\"\n",
    "batch_size = 256\n",
    "\n",
    "# We train each model according to the indices\n",
    "for i in range(len(models)):\n",
    "    print(\"Training model: \", model_names[i])\n",
    "\n",
    "    # We define the training and testing sets according to the indices\n",
    "    x_train, y_train = train_data[:, indices_list[i][0]:indices_list[i][1]], train_data[:, 1]\n",
    "    x_test, y_test = test_data[:, indices_list[i][0]:indices_list[i][1]], test_data[:, 1]\n",
    "    \n",
    "    # We define the generators\n",
    "    train_generator = SlidingWindowDataGenerator(x_train, y_train, window_size_list[i], batch_size)\n",
    "    valid_generator = SlidingWindowDataGenerator(x_test, y_test, window_size_list[i], batch_size)\n",
    "\n",
    "    # We train the model\n",
    "    history = models[i].fit(train_generator, validation_data=valid_generator, epochs=10, verbose=1)\n",
    "    histories.append(history)\n",
    "\n",
    "    # We save the model\n",
    "    models[i].save(model_names[i] + '.h5')\n",
    "\n",
    "    # We save the history\n",
    "    with open(model_names[i] + '_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    # We predict the test set and stack it vertically to the test_data array\n",
    "    # We use the slinding window generator to predict the test set, but we do not shuffle the data\n",
    "    test_generator_pred = SlidingWindowDataGenerator(x_test, y_test, window_size_list[i], batch_size, shuffle=False)\n",
    "    y_pred = models[i].predict(test_generator_pred, verbose=1)\n",
    "\n",
    "    # The sliding window generator stops 7 frames before the end of the test set, so we add 7 zeros to the end of the prediction\n",
    "    # Remember that the train and test data is padded anyway\n",
    "    y_pred = np.vstack((y_pred, np.zeros((7, y_pred.shape[1]))))\n",
    "\n",
    "    # Round the predictions\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # Notice that since we are using the indices, the test_data used to train the next model will not be different\n",
    "    test_data = np.hstack((test_data, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We only use the following code if we want to reload the model to do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model:  cnn_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 19:32:12.122298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 21s 16ms/step\n",
      "Reloading model:  cnn_mfcc\n",
      "   5/1247 [..............................] - ETA: 15s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 19:32:33.627971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 13s 11ms/step\n",
      "Reloading model:  cnn_f0\n",
      "   7/1247 [..............................] - ETA: 11s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 19:32:47.905921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 14s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "batch_size = 256\n",
    "\n",
    "# Reaload each model and do the predictions\n",
    "for i in range(len(models)):\n",
    "    print(\"Reloading model: \", model_names[i])\n",
    "\n",
    "    # Clear previous session\n",
    "    from keras import backend as K\n",
    "\n",
    "    # We reload the model\n",
    "    models[i] = load_model(model_names[i] + '.h5')\n",
    "\n",
    "    # We reload the model\n",
    "    models[i] = load_model(model_names[i] + '.h5')\n",
    "\n",
    "    # We define the training and testing sets according to the indices\n",
    "    x_test, _ = test_data[:, indices_list[i][0]:indices_list[i][1]], test_data[:, 1]\n",
    "\n",
    "    # We predict the test set and stack it vertically to the test_data array\n",
    "    # We use the slinding window generator to predict the test set, but we do not shuffle the data\n",
    "\n",
    "    pred_generator = SlidingWindowDataGeneratorPrediction(x_test, window_size_list[i], batch_size)\n",
    "    y_pred = models[i].predict(pred_generator, verbose=1)\n",
    "\n",
    "    # The sliding window generator stops 7 frames before the end of the test set\n",
    "    # Also, the first prediction is done for index 3, so we add 3 rows of zeros to the beginning of the prediction and 4 rows of zeros to the end\n",
    "    # Add 3 zeros to the beginning of the prediction\n",
    "    y_pred = np.vstack((np.zeros((3, y_pred.shape[1])), y_pred))\n",
    "    # Add 4 zeros to the end of the prediction\n",
    "    y_pred = np.vstack((y_pred, np.zeros((4, y_pred.shape[1]))))\n",
    "\n",
    "    # Round the predictions\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # Notice that since we are using the indices, the test_data used to train the next model will not be different\n",
    "    if i == 0:\n",
    "        test_data_predicted = np.hstack((test_data, y_pred))\n",
    "    else:\n",
    "        test_data_predicted = np.hstack((test_data_predicted, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319223, 18)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319223, 41)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the test_data\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 41: [ 0.  1. nan]\n",
      "Number of 1s in column 41: 227975\n",
      "Number of 0s in column 41: 90247\n",
      "Number of nans in column 41: 1001\n",
      "Unique values in column 42: [0. 1.]\n",
      "Number of 1s in column 42: 164085\n",
      "Number of 0s in column 42: 155138\n",
      "Number of nans in column 42: 0\n",
      "Unique values in column 43: [ 0.  1. nan]\n",
      "Number of 1s in column 43: 245428\n",
      "Number of 0s in column 43: 72794\n",
      "Number of nans in column 43: 1001\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values qe have in the last three columns with a for loop and print\n",
    "for i in range(3):\n",
    "    print(\"Unique values in column {}: {}\".format(i+41, np.unique(test_data_predicted[:,i+41])))\n",
    "    # We need also to check the number of 1s and 0s, and nan values\n",
    "    print(\"Number of 1s in column {}: {}\".format(i+41, np.sum(test_data_predicted[:,i+41]==1)))\n",
    "    print(\"Number of 0s in column {}: {}\".format(i+41, np.sum(test_data_predicted[:,i+41]==0)))\n",
    "    print(\"Number of nans in column {}: {}\".format(i+41, np.sum(np.isnan(test_data_predicted[:,i+41]))))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild the test_data in hdf5 file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Contenu des colonnes :\n",
    "0   :   timeframes\n",
    "1   :   creaky_voice_decision\n",
    "2   :   bana_resampled\n",
    "3   :   opensmile_resampled\n",
    "4   :   pefac_resampled\n",
    "5   :   praat_ac_resampled\n",
    "6   :   praat_cc_resampled\n",
    "7   :   praat_shs_resampled\n",
    "8   :   pyin_resampled\n",
    "9   :   rapt_resampled\n",
    "10  :   srh_resampled\n",
    "11  :   straight_resampled\n",
    "12  :   swipe_resampled\n",
    "13  :   swipep_resampled\n",
    "14  :   yaapt_resampled\n",
    "15  :   yin_resampled\n",
    "16  :   hnr_resampled\n",
    "17  :   cpps_resampled\n",
    "18  :   praat_intensity_resampled\n",
    "19  :   praat_se_resampled\n",
    "20  :   mfcc_01\n",
    "21  :   mfcc_02\n",
    "22  :   mfcc_03\n",
    "23  :   mfcc_04\n",
    "24  :   mfcc_05\n",
    "25  :   mfcc_06\n",
    "26  :   mfcc_07\n",
    "27  :   mfcc_08\n",
    "28  :   mfcc_09\n",
    "29  :   mfcc_10\n",
    "30  :   mfcc_11\n",
    "31  :   mfcc_12\n",
    "32  :   mfcc_13\n",
    "33  :   mfcc_14\n",
    "34  :   mfcc_15\n",
    "35  :   mfcc_16\n",
    "36  :   mfcc_17\n",
    "37  :   mfcc_18\n",
    "38  :   mfcc_19\n",
    "39  :   mfcc_20\n",
    "40  :   group_index / file_index\n",
    "41  :   model_pred_all\n",
    "42  :   model_pred_mfcc\n",
    "43  :   model_pred_f0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371551, 44)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of the test_data_test array\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([265., 265., 265., ..., 102., 102., 102.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check where the indices are\n",
    "test_data[:, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to rebuild the the hdf5 file with the dataset and the predictions\n",
    "# We first create the hdf5 file\n",
    "hdf5_file = h5py.File('/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.1. F0 final/TODOS_resampled_5ms_VD-predictions_20231116.hdf5', 'w')\n",
    "\n",
    "# Each group in the hdf5 file will be a file. For that we will use the group_index column(40-th index) and the group_dict dictionary alrealdy defined\n",
    "# We iterate over the test_data_test array and create the groups\n",
    "\n",
    "# We have to subset the test_data array based on the repeating indices in the 40-th column:\n",
    "# We get the unique indices\n",
    "unique_indices = np.unique(test_data_predicted[:, 40])\n",
    "# We iterate over the unique indices and subset the test_data array\n",
    "for i in range(len(unique_indices)):\n",
    "    # We subset the test_data array\n",
    "    test_data_subset = test_data_predicted[test_data_predicted[:, 40] == unique_indices[i]]\n",
    "\n",
    "    # We need to round up values in column 1 to 0 or 1\n",
    "    test_data_subset[:, 1] = np.round(test_data_subset[:, 1])\n",
    "\n",
    "    # Before saving the data, we need to unpad each subset by cutting off:\n",
    "    # 1. The first 3 rows\n",
    "    test_data_subset = test_data_subset[3:, :]\n",
    "    # 2. The last 4 rows\n",
    "    test_data_subset = test_data_subset[:-4, :]\n",
    "    # We get the group name in the group_dict dictionary\n",
    "    group_name = group_dict[unique_indices[i]]\n",
    "    # We create the group\n",
    "    group = hdf5_file.create_dataset(group_name, data=test_data_subset)\n",
    "\n",
    "# We close the hdf5 file\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfamcv01__002__GIL (1846, 44)\n",
      "bfamcv01__019__EVN (479, 44)\n",
      "bfamcv01__048__EVN (621, 44)\n",
      "bfamcv01__051__LUI (427, 44)\n",
      "bfamcv01__054__EVN (593, 44)\n",
      "bfamcv01__062__GIL (365, 44)\n",
      "bfamcv01__068__GIL (325, 44)\n",
      "bfamcv01__127__LEO (1641, 44)\n",
      "bfamcv01__141__EVN (554, 44)\n",
      "bfamcv01__142__GIL (303, 44)\n",
      "bfamcv01__149__LUI (2714, 44)\n",
      "bfamcv01__186__EVN (504, 44)\n",
      "bfamcv01__239__EVN (535, 44)\n",
      "bfamcv02_234_274631_0_276705_0_NOSSA (535, 44)\n",
      "bfamcv02__043__RUT (506, 44)\n",
      "bfamcv02__044__TER (1073, 44)\n",
      "bfamcv02__045__RUT (495, 44)\n",
      "bfamcv02__063__RUT (444, 44)\n",
      "bfamcv02__092__RUT (388, 44)\n",
      "bfamcv02__096__TER (577, 44)\n",
      "bfamcv02__141__TER (468, 44)\n",
      "bfamcv02__162__RUT (297, 44)\n",
      "bfamcv02__178__TER (690, 44)\n",
      "bfamcv02__192__RUT (952, 44)\n",
      "bfamcv02__193__RUT (689, 44)\n",
      "bfamcv02__202__RUT (1282, 44)\n",
      "bfamcv02__224__RUT (532, 44)\n",
      "bfamcv02__231__TER (474, 44)\n",
      "bfamcv02__246__TER (1196, 44)\n",
      "bfamcv02__264__TER (428, 44)\n",
      "bfamcv02__304__TER (456, 44)\n",
      "bfamcv02__315__RUT (439, 44)\n",
      "bfamcv02__317__TER (589, 44)\n",
      "bfamcv03__001__CEL (339, 44)\n",
      "bfamcv03__011__REN (631, 44)\n",
      "bfamcv03__020__REN (427, 44)\n",
      "bfamcv03__023__TON (376, 44)\n",
      "bfamcv03__026__REN (564, 44)\n",
      "bfamcv03__045__CEL (235, 44)\n",
      "bfamcv03__049__REN (318, 44)\n",
      "bfamcv03__054__CAR (308, 44)\n",
      "bfamcv03__063__CEL (365, 44)\n",
      "bfamcv03__098__CAR (280, 44)\n",
      "bfamcv03__111__CAR (535, 44)\n",
      "bfamcv03__116__CEL (283, 44)\n",
      "bfamcv03__118__TON (518, 44)\n",
      "bfamcv03__119__TON (359, 44)\n",
      "bfamcv03__129__CEL (332, 44)\n",
      "bfamcv03__130__CEL (361, 44)\n",
      "bfamcv03__138__TON (518, 44)\n",
      "bfamcv03__139__REN (393, 44)\n",
      "bfamcv03__169__CAR (216, 44)\n",
      "bfamcv03__188__TON (511, 44)\n",
      "bfamcv03__189__CEL (348, 44)\n",
      "bfamcv03__195__CAR (518, 44)\n",
      "bfamcv03__199__CAR (569, 44)\n",
      "bfamcv03__203__CEL (434, 44)\n",
      "bfamcv03__207__CAR (311, 44)\n",
      "bfamcv03__211__TON (267, 44)\n",
      "bfamcv03__215__TON (316, 44)\n",
      "bfamcv03__218__CAR (439, 44)\n",
      "bfamcv03__225__CEL (352, 44)\n",
      "bfamcv03__227__CAR (607, 44)\n",
      "bfamcv03__247__TON (483, 44)\n",
      "bfamcv03__277__CAR (524, 44)\n",
      "bfamcv03__282__CAR (407, 44)\n",
      "bfamcv03__289__CEL (263, 44)\n",
      "bfamcv04_49_41998_0_43335_0_NOSSA (388, 44)\n",
      "bfamcv04__006__LUC (414, 44)\n",
      "bfamcv04__010__LUC (532, 44)\n",
      "bfamcv04__018__HEL (303, 44)\n",
      "bfamcv04__048__BRU (422, 44)\n",
      "bfamcv04__050__HEL (388, 44)\n",
      "bfamcv04__075__LUC (1312, 44)\n",
      "bfamcv04__137__HEL (347, 44)\n",
      "bfamcv04__169__BRU (509, 44)\n",
      "bfamcv04__189__BRU (1162, 44)\n",
      "bfamcv04__201__HEL (595, 44)\n",
      "bfamcv04__241__HEL (443, 44)\n",
      "bfamcv04__257__HEL (809, 44)\n",
      "bfamcv04__300__BRU (291, 44)\n",
      "bfamcv04__384__BRU (432, 44)\n",
      "bfamcv04__389__CEL (474, 44)\n",
      "bfamcv05_141_177207_0_178275_0_NOSSA (334, 44)\n",
      "bfamcv05_155_193301_0_193956_0_EXPER (251, 44)\n",
      "bfamcv05_256_342091_0_342895_0_EXPER (281, 44)\n",
      "bfamcv06_8_4496_0_5413_0_NOSSA (304, 44)\n",
      "bfamcv07_114_192060_0_195698_0_NAMES (848, 44)\n",
      "bfamcv08_229_366539_0_367877_0_NAMES (388, 44)\n",
      "bfamcv10_122_197691_0_199800_0_EXPER (542, 44)\n",
      "bfamcv10_202_347118_0_352449_0_EXPER (1187, 44)\n",
      "bfamcv10_51_74973_0_78099_0_EXPER (746, 44)\n",
      "bfamcv11_161_310649_0_311479_0_NAMES (286, 44)\n",
      "bfamcv11_2_1801_0_6543_0_NAMES (1069, 44)\n",
      "bfamcv11_41_86166_0_88002_0_EXPER (488, 44)\n",
      "bfamcv13_4_6918_0_8700_0_NOSSA (477, 44)\n",
      "bfamcv14_171_272033_0_274820_0_NAMES (678, 44)\n",
      "bfamcv15_112_165953_0_167199_0_NAMES (370, 44)\n",
      "bfamcv15_198_285289_0_286154_0_NAMES (294, 44)\n",
      "bfamcv16_184_212261_0_213819_0_NOSSA (432, 44)\n",
      "bfamcv16_27_35951_0_38464_0_NOSSA (623, 44)\n",
      "bfamcv16_51_67126_0_72134_0_NOSSA (1122, 44)\n",
      "bfamcv18_106_695279_0_697284_0_NOSSA (522, 44)\n",
      "bfamcv18_141_866021_0_867841_0_NOSSA (484, 44)\n",
      "bfamcv18_161_941010_0_941731_0_NAMES (265, 44)\n",
      "bfamcv18_175_974885_0_976622_0_NAMES (468, 44)\n",
      "bfamcv18_189_1056130_0_1057660_0_NAMES (426, 44)\n",
      "bfamcv18_208_1092060_0_1093150_0_NAMES (338, 44)\n",
      "bfamcv18_58_476983_0_480866_0_NAMES (897, 44)\n",
      "bfamcv18_79_540422_0_543160_0_NAMES (668, 44)\n",
      "bfamcv18_81_544237_0_547454_0_NAMES (764, 44)\n",
      "bfamcv20_54_77809_0_79415_0_NOSSA (442, 44)\n",
      "bfamcv22_127_196721_0_197906_0_NOSSA (357, 44)\n",
      "bfamcv22_152_223693_0_225120_0_NAMES (406, 44)\n",
      "bfamcv22_189_319243_0_321268_0_NOSSA (525, 44)\n",
      "bfamcv22_1_753_0_1870_0_EXPER (344, 44)\n",
      "bfamcv22_21_32079_0_35724_0_EXPER (850, 44)\n",
      "bfamcv22_243_639744_0_641677_0_NOSSA (507, 44)\n",
      "bfamcv22_36_48217_0_49027_0_NOSSA (282, 44)\n",
      "bfamcv23_260_380175_0_380800_0_NOSSA (246, 44)\n",
      "bfamcv24_171_222996_0_224695_0_NAMES (460, 44)\n",
      "bfamcv24_277_361522_0_363650_0_NOSSA (546, 44)\n",
      "bfamcv24_295_388369_0_389357_0_NAMES (318, 44)\n",
      "bfamcv24_36_45819_0_47406_0_NAMES (438, 44)\n",
      "bfamcv25_60_101422_0_104040_0_EXPER (644, 44)\n",
      "bfamcv26_167_266847_0_267930_0_NAMES (337, 44)\n",
      "bfamcv26_242_387236_0_388637_0_NAMES (401, 44)\n",
      "bfamcv26_262_406623_0_412257_0_EXPER (1108, 44)\n",
      "bfamcv27_114_118806_0_120671_0_NOSSA (494, 44)\n",
      "bfamcv27_13_8483_0_11826_0_NAMES (789, 44)\n",
      "bfamcv27_169_176258_0_176950_0_NAMES (259, 44)\n",
      "bfamcv27_228_235115_0_237181_0_NAMES (534, 44)\n",
      "bfamcv27_274_275597_0_277538_0_NOSSA (509, 44)\n",
      "bfamcv27_334_331697_0_333495_0_NOSSA (480, 44)\n",
      "bfamcv27_89_88218_0_89577_0_NAMES (392, 44)\n",
      "bfamcv28_262_398627_0_407290_0_EXPER (1853, 44)\n",
      "bfamcv32_154_235174_0_236040_0_EXPER (294, 44)\n",
      "bfamcv32_212_312547_0_314275_0_EXPER (466, 44)\n",
      "bfamcv33_117_114114_0_116345_0_NAMES (567, 44)\n",
      "bfamcv33_157_159649_0_161623_0_NOSSA (515, 44)\n",
      "bfamcv33_166_173616_0_175751_0_EXPER (548, 44)\n",
      "bfamcv33_213_221387_0_222506_0_NAMES (344, 44)\n",
      "bfamcv33_311_304571_0_305974_0_EXPER (401, 44)\n",
      "bfamcv33_392_411543_0_413159_0_NOSSA (444, 44)\n",
      "bfamcv33_414_453377_0_454921_0_NOSSA (429, 44)\n",
      "bfamdl01_18_25816_0_26964_0_NOSSA (350, 44)\n",
      "bfamdl01_94_114463_0_116065_0_NOSSA (441, 44)\n",
      "bfamdl01__018__FLA (339, 44)\n",
      "bfamdl01__037__FLA (438, 44)\n",
      "bfamdl01__061__MDS (554, 44)\n",
      "bfamdl01__096__REN (514, 44)\n",
      "bfamdl01__097__FLA (721, 44)\n",
      "bfamdl01__117__FLA (481, 44)\n",
      "bfamdl01__160__REN (312, 44)\n",
      "bfamdl01__192__FLA (481, 44)\n",
      "bfamdl01__199__REN (326, 44)\n",
      "bfamdl01__231__REN (523, 44)\n",
      "bfamdl01__241__REN (395, 44)\n",
      "bfamdl01__260__FLA (356, 44)\n",
      "bfamdl01__261__REN (515, 44)\n",
      "bfamdl01__266__FLA (572, 44)\n",
      "bfamdl01__270__FLA (887, 44)\n",
      "bfamdl01__322__FLA (361, 44)\n",
      "bfamdl01__364__REN (738, 44)\n",
      "bfamdl01__407__FLA (474, 44)\n",
      "bfamdl01__428__FLA (429, 44)\n",
      "bfamdl01__459__FLA (412, 44)\n",
      "bfamdl01__462__REN (401, 44)\n",
      "bfamdl01__473__FLA (401, 44)\n",
      "bfamdl01__535__REN (435, 44)\n",
      "bfamdl01__567__FLA (441, 44)\n",
      "bfamdl02__027__BAL (499, 44)\n",
      "bfamdl02__038__BAL (456, 44)\n",
      "bfamdl02__068__BEL (449, 44)\n",
      "bfamdl02__071__BAL (408, 44)\n",
      "bfamdl02__075__BAL (793, 44)\n",
      "bfamdl02__076__BEL (367, 44)\n",
      "bfamdl02__109__BAL (464, 44)\n",
      "bfamdl02__117__BEL (470, 44)\n",
      "bfamdl02__129__BEL (668, 44)\n",
      "bfamdl02__152__BAL (464, 44)\n",
      "bfamdl02__197__BAL (444, 44)\n",
      "bfamdl02__206__BEL (613, 44)\n",
      "bfamdl02__209__BAL (861, 44)\n",
      "bfamdl02__212__BAL (403, 44)\n",
      "bfamdl02__215__BEL (714, 44)\n",
      "bfamdl02__218__BAL (344, 44)\n",
      "bfamdl02__222__BEL (586, 44)\n",
      "bfamdl02__228__BEL (303, 44)\n",
      "bfamdl02__254__BEL (1015, 44)\n",
      "bfamdl02__256__BEL (758, 44)\n",
      "bfamdl02__257__BAL (341, 44)\n",
      "bfamdl02__273__BAL (566, 44)\n",
      "bfamdl02__283__BEL (452, 44)\n",
      "bfamdl03__002__LUZ (504, 44)\n",
      "bfamdl03__003__LUZ (738, 44)\n",
      "bfamdl03__031__LUZ (380, 44)\n",
      "bfamdl03__037__LUZ (617, 44)\n",
      "bfamdl03__046__LUZ (532, 44)\n",
      "bfamdl03__065__LAU (537, 44)\n",
      "bfamdl03__095__LUZ (638, 44)\n",
      "bfamdl03__102__LUZ (319, 44)\n",
      "bfamdl03__104__LUZ (1564, 44)\n",
      "bfamdl03__106__LAU (568, 44)\n",
      "bfamdl03__108__LUZ (443, 44)\n",
      "bfamdl03__112__LAU (428, 44)\n",
      "bfamdl03__119__LUZ (692, 44)\n",
      "bfamdl03__133__LUZ (309, 44)\n",
      "bfamdl03__139__LUZ (435, 44)\n",
      "bfamdl03__144__LUZ (354, 44)\n",
      "bfamdl03__185__LAU (600, 44)\n",
      "bfamdl03__206__LUZ (452, 44)\n",
      "bfamdl03__208__LUZ (596, 44)\n",
      "bfamdl03__225__LUZ (648, 44)\n",
      "bfamdl03__228__LAU (652, 44)\n",
      "bfamdl03__276__LUZ (1014, 44)\n",
      "bfamdl03__281__LUZ (401, 44)\n",
      "bfamdl03__306__LUZ (412, 44)\n",
      "bfamdl03__307__LUZ (384, 44)\n",
      "bfamdl04__024__SIL (457, 44)\n",
      "bfamdl04__064__ERN (489, 44)\n",
      "bfamdl04__072__KAT (406, 44)\n",
      "bfamdl04__132__KAT (342, 44)\n",
      "bfamdl04__167__SIL (547, 44)\n",
      "bfamdl04__169__SIL (553, 44)\n",
      "bfamdl04__191__SIL (710, 44)\n",
      "bfamdl05__120__CES (384, 44)\n",
      "bfamdl05__123__ANE (391, 44)\n",
      "bfamdl05__168__CES (513, 44)\n",
      "bfamdl05__181__CES (527, 44)\n",
      "bfamdl05__258__CES (384, 44)\n",
      "bfamdl05__267__CES (452, 44)\n",
      "bfamdl05__297__ANE (484, 44)\n",
      "bfamdl05__313__CES (365, 44)\n",
      "bfamdl05__389__CES (461, 44)\n",
      "bfamdl05__400__ANE (286, 44)\n",
      "bfamdl08_131_254960_0_256252_0_NOSSA (379, 44)\n",
      "bfamdl08_201_364957_0_366206_0_NOSSA (370, 44)\n",
      "bfamdl08_202_368687_0_374448_0_NOSSA (1273, 44)\n",
      "bfamdl08_305_540428_0_541970_0_NOSSA (429, 44)\n",
      "bfamdl09_128_256637_0_258048_0_NOSSA (403, 44)\n",
      "bfamdl09_554_911640_0_913294_0_NOSSA (451, 44)\n",
      "bfamdl09_646_1042920_0000000001_1044500_0_NOSSA (436, 44)\n",
      "bfamdl10_192_274115_0_275707_0_NOSSA (439, 44)\n",
      "bfamdl10_36_53833_0_56175_0_NAMES (589, 44)\n",
      "bfamdl11_133_257726_0_258846_0_NAMES (344, 44)\n",
      "bfamdl13_100_180591_0_181942_0_NOSSA (391, 44)\n",
      "bfamdl13_73_105829_0_106903_0_NOSSA (335, 44)\n",
      "bfamdl16_110_203996_0_205833_0_NAMES (488, 44)\n",
      "bfamdl16_14_26967_0_27839_0_NAMES (295, 44)\n",
      "bfamdl16_166_304449_0_305756_0_NOSSA (382, 44)\n",
      "bfamdl16_199_346336_0_348559_0_NOSSA (565, 44)\n",
      "bfamdl16_1_384_0_1819_0_NAMES (407, 44)\n",
      "bfamdl16_217_375811_0_380161_0_EXPER (990, 44)\n",
      "bfamdl16_57_104308_0_110630_0_NAMES (1385, 44)\n",
      "bfamdl17_132_223748_0_225340_0_EXPER (439, 44)\n",
      "bfamdl17_67_94041_0_95610_0_NAMES (434, 44)\n",
      "bfamdl18_176_301394_0_305501_0_NOSSA (942, 44)\n",
      "bfamdl18_223_382290_0_384533_0_NAMES (569, 44)\n",
      "bfamdl18_260_447528_0_450612_0_NAMES (737, 44)\n",
      "bfamdl18_265_457541_0_459369_0_NAMES (486, 44)\n",
      "bfamdl20_129_324815_0_326178_0_NOSSA (393, 44)\n",
      "bfamdl20_194_459993_0_461070_0_NOSSA (336, 44)\n",
      "bfamdl21_47_112724_0_114936_0_EXPER (563, 44)\n",
      "bfamdl22_1_485_0_2004_0 (424, 44)\n",
      "bfamdl22_90_274866_0_277808_0_EXPER (709, 44)\n",
      "bfamdl23_116_375099_0_378009_0_NOSSA (702, 44)\n",
      "bfamdl23_54_172439_0_173606_0_NOSSA (354, 44)\n",
      "bfamdl25_111_156217_0_158516_0_EXPER (580, 44)\n",
      "bfamdl25_162_232601_0_235346_0_NOSSA (669, 44)\n",
      "bfamdl26_236_451645_0_454530_0_NOSSA (698, 44)\n",
      "bfamdl26_275_543230_0_545492_0_EXPER (573, 44)\n",
      "bfamdl26_67_129000_0_131664_0_EXPER (653, 44)\n",
      "bfamdl27_201_387685_0_389038_0_NOSSA (391, 44)\n",
      "bfamdl27_233_459315_0_461780_0_EXPER (614, 44)\n",
      "bfamdl27_8_11158_0_12706_0_NAMES (430, 44)\n",
      "bfamdl28_156_379159_0_381517_0_EXPER (592, 44)\n",
      "bfamdl28_78_174983_0_177017_0_EXPER (527, 44)\n",
      "bfamdl30_159_362191_0_367724_0_NOSSA (1227, 44)\n",
      "bfamdl31_122_175376_0_176355_0_NAMES (316, 44)\n",
      "bfamdl31_316_584645_0_585685_0_NAMES (328, 44)\n",
      "bfamdl31_437_979452_0_982196_0_NAMES (669, 44)\n",
      "bfamdl31_438_982191_0_984662_0_EXPER (615, 44)\n",
      "bfamdl34_208_371062_0_372961_0_NAMES (500, 44)\n",
      "bfammn01__006__MAI (1872, 44)\n",
      "bfammn01__008__MAI (872, 44)\n",
      "bfammn01__089__MAI (515, 44)\n",
      "bfammn01__092__DUD (1147, 44)\n",
      "bfammn02__001__LUC (2602, 44)\n",
      "bfammn02__012__DFL (2038, 44)\n",
      "bfammn02__026__DFL (570, 44)\n",
      "bfammn02__030__DFL (786, 44)\n",
      "bfammn02__080__DFL (593, 44)\n",
      "bfammn02__101__DFL (1340, 44)\n",
      "bfammn02__138__DFL (2776, 44)\n",
      "bfammn02__181__DFL (754, 44)\n",
      "bfammn03__040__ALO (559, 44)\n",
      "bfammn03__078__ALO (566, 44)\n",
      "bfammn03__093__ALO (3850, 44)\n",
      "bfammn03__101__ALO (379, 44)\n",
      "bfammn03__106__ALO (856, 44)\n",
      "bfammn03__111__ALO (1434, 44)\n",
      "bfammn03__125__ALO (2303, 44)\n",
      "bfammn04__004__REG (278, 44)\n",
      "bfammn04__013__REG (712, 44)\n",
      "bfammn04__021__REG (2254, 44)\n",
      "bfammn04__023__REG (673, 44)\n",
      "bfammn04__027__REG (454, 44)\n",
      "bfammn04__029__REG (1302, 44)\n",
      "bfammn04__038__REG (495, 44)\n",
      "bfammn04__044__REG (1046, 44)\n",
      "bfammn04__048__REG (581, 44)\n",
      "bfammn04__084__REG (1255, 44)\n",
      "bfammn04__085__REG (489, 44)\n",
      "bfammn04__087__REG (456, 44)\n",
      "bfammn04__104__REG (1441, 44)\n",
      "bfammn04__111__REG (1399, 44)\n",
      "bfammn04__114__REG (1177, 44)\n",
      "bfammn04__117__REG (274, 44)\n",
      "bfammn04__138__REG (467, 44)\n",
      "bfammn04__140__REG (1313, 44)\n",
      "bfammn04__151__REG (390, 44)\n",
      "bfammn05__001__CAR (1056, 44)\n",
      "bfammn05__022__CAR (3873, 44)\n",
      "bfammn05__045__CAR (4218, 44)\n",
      "bfammn05__090__CAR (1059, 44)\n",
      "bfammn05__092__CAR (1709, 44)\n",
      "bfammn05__102__JUN (490, 44)\n",
      "bfammn06__006__JOR (2405, 44)\n",
      "bfammn06__022__JOR (1257, 44)\n",
      "bfammn06__037__JOR (897, 44)\n",
      "bfammn06__042__JOR (933, 44)\n",
      "bfammn06__048__JOR (2862, 44)\n",
      "bfammn06__049__JOR (3210, 44)\n",
      "bfammn07_150_489706_0_491666_0_NAMES (512, 44)\n",
      "bfammn10_107_239707_0_240445_0_NOSSA (268, 44)\n",
      "bfammn10_68_181911_0_186582_0_NOSSA (1055, 44)\n",
      "bfammn12_177_380133_0_385992_0_EXPER (1292, 44)\n",
      "bfammn12_204_428565_0_431334_0_NOSSA (674, 44)\n",
      "bfammn12_211_437099_0_439132_0_NOSSA (527, 44)\n",
      "bfammn13_20_92070_0_93383_0_NOSSA (383, 44)\n",
      "bfammn18_35_230110_0_231893_0_NAMES (477, 44)\n",
      "bfammn26_15_22274_0_28599_0_EXPER (1385, 44)\n",
      "bfammn30_75_425952_0_429153_0_EXPER (761, 44)\n",
      "bfammn33_120_271169_0_278179_0_NOSSA (1522, 44)\n",
      "bfammn34_2_320_0_1088_0_NAMES (274, 44)\n",
      "bfammn35_148_393018_0_394438_0_NAMES (404, 44)\n",
      "bfammn35_93_230838_0_233642_0_NOSSA (681, 44)\n",
      "bpubcv01__001__FLA (580, 44)\n",
      "bpubcv01__012__EMM (1550, 44)\n",
      "bpubcv01__021__FLA (835, 44)\n",
      "bpubcv01__193__FLA (305, 44)\n",
      "bpubcv01__209__BRU (320, 44)\n",
      "bpubcv01__252__FLA (422, 44)\n",
      "bpubcv01__358__BRU (491, 44)\n",
      "bpubcv02__024__CAR (900, 44)\n",
      "bpubcv02__045__OSV (456, 44)\n",
      "bpubcv02__073__CAR (468, 44)\n",
      "bpubcv02__139__OSV (461, 44)\n",
      "bpubcv02__155__OSV (388, 44)\n",
      "bpubcv02__177__OSV (320, 44)\n",
      "bpubcv02__233__TIQ (257, 44)\n",
      "bpubcv02__250__OSV (675, 44)\n",
      "bpubcv04_161_337474_0_338754_0_NAMES (376, 44)\n",
      "bpubcv04_16_26081_0_27168_0_NAMES (338, 44)\n",
      "bpubcv05_205_349787_0_351686_0_EXPER (500, 44)\n",
      "bpubcv07_175_278657_0_279709_0_NAMES (331, 44)\n",
      "bpubdl01__031__PAU (737, 44)\n",
      "bpubdl01__043__PAU (429, 44)\n",
      "bpubdl01__046__PAU (343, 44)\n",
      "bpubdl01__070__PAU (607, 44)\n",
      "bpubdl01__075__PAU (767, 44)\n",
      "bpubdl01__078__PAU (1597, 44)\n",
      "bpubdl01__099__PAU (713, 44)\n",
      "bpubdl01__119__PAU (420, 44)\n",
      "bpubdl01__121__PAU (559, 44)\n",
      "bpubdl01__122__PAU (753, 44)\n",
      "bpubdl01__134__PAU (348, 44)\n",
      "bpubdl01__138__PAU (763, 44)\n",
      "bpubdl01__163__PAU (1344, 44)\n",
      "bpubdl01__174__PAU (568, 44)\n",
      "bpubdl01__177__PAU (1184, 44)\n",
      "bpubdl01__192__PAU (936, 44)\n",
      "bpubdl01__210__ROG (576, 44)\n",
      "bpubdl01__211__PAU (968, 44)\n",
      "bpubdl01__226__PAU (588, 44)\n",
      "bpubdl01__247__PAU (1211, 44)\n",
      "bpubdl01__254__PAU (809, 44)\n",
      "bpubdl01__258__PAU (1102, 44)\n",
      "bpubdl02__013__EUG (467, 44)\n",
      "bpubdl02__023__EUG (496, 44)\n",
      "bpubdl02__054__JAN (319, 44)\n",
      "bpubdl02__070__EUG (541, 44)\n",
      "bpubdl02__114__EUG (866, 44)\n",
      "bpubdl02__139__EUG (541, 44)\n",
      "bpubdl02__156__EUG (523, 44)\n",
      "bpubdl02__175__WOA (580, 44)\n",
      "bpubdl02__210__EUG (558, 44)\n",
      "bpubdl02__215__EUG (410, 44)\n",
      "bpubdl02__224__EUG (575, 44)\n",
      "bpubdl02__258__EUG (677, 44)\n",
      "bpubdl02__280__EUG (558, 44)\n",
      "bpubdl02__290__JAN (478, 44)\n",
      "bpubdl02__300__EUG (461, 44)\n",
      "bpubdl03_206_676304_0_677924_0_NOSSA (445, 44)\n",
      "bpubdl05_247_383211_0_383980_0_NAMES (274, 44)\n",
      "bpubdl05_248_383836_0_384786_0_EXPER (310, 44)\n",
      "bpubdl05_73_94092_0_95232_0_NAMES (348, 44)\n",
      "bpubdl06_236_447302_0_449561_0_NOSSA (572, 44)\n",
      "bpubdl08_226_306175_0_308672_0_NOSSA (620, 44)\n",
      "bpubdl08_242_319330_0_331311_0_NAMES (2517, 44)\n",
      "bpubdl08_246_334567_0_339261_0_NOSSA (1059, 44)\n",
      "bpubdl10_29_74803_0_84790_0_NAMES (2118, 44)\n",
      "bpubdl11_292_570247_0_573164_0_EXPER (704, 44)\n",
      "bpubmn01_81_396187_0_400133_0_NOSSA (910, 44)\n",
      "bpubmn01__001__LUA (3431, 44)\n",
      "bpubmn01__004__SHE (2395, 44)\n",
      "bpubmn01__006__SHE (4346, 44)\n",
      "bpubmn01__018__SHE (2773, 44)\n",
      "bpubmn01__018__SHE_completo (4137, 44)\n",
      "bpubmn01__024__SHE (266, 44)\n",
      "bpubmn01__026__SHE (1209, 44)\n",
      "bpubmn01__032__SHE (444, 44)\n",
      "bpubmn01__041__SHE (552, 44)\n",
      "bpubmn01__046__SHE (1490, 44)\n",
      "bpubmn01__048__SHE (6814, 44)\n",
      "bpubmn01__049__SHE (924, 44)\n",
      "bpubmn01__053__SHE (2152, 44)\n",
      "bpubmn01__057__SHE (1717, 44)\n",
      "bpubmn01__066__SHE (1213, 44)\n",
      "bpubmn01__068__SHE (741, 44)\n",
      "bpubmn01__073__SHE (1063, 44)\n",
      "bpubmn01__085__SHE (1750, 44)\n",
      "bpubmn01__093__SHE (1200, 44)\n",
      "bpubmn01__097__SHE (1244, 44)\n",
      "bpubmn01__098__SHE (454, 44)\n",
      "bpubmn01__110__SHE (768, 44)\n",
      "bpubmn10_13_70417_0_71030_0_NAMES (243, 44)\n",
      "bpubmn11_74_218151_0_220548_0_NOSSA (600, 44)\n"
     ]
    }
   ],
   "source": [
    "# We check that the groups are created properly by opening the hdf5 file with h5py.File('test_data_keele-cst.hdf5', 'r')\n",
    "# We can also check the shape of each group by using the .shape attribute\n",
    "# Open the hdf5 file\n",
    "hdf5_file = h5py.File('/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.1. F0 final/TODOS_resampled_5ms_VD-predictions_20231116.hdf5', 'r')\n",
    "\n",
    "# Get group keys\n",
    "group_keys = list(hdf5_file.keys())\n",
    "# Iterate over the group keys and print the shape of each group\n",
    "for i in range(len(group_keys)):\n",
    "    print(group_keys[i], hdf5_file[group_keys[i]].shape)\n",
    "\n",
    "# Close the hdf5 file\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 40)\n",
      "(454, 44)\n",
      "We're good to go!\n"
     ]
    }
   ],
   "source": [
    "# We want to test if file f1nw0000_16kHz_ImpResp_Classroom_+10dB has the same shape as in the raw data file\n",
    "# We open the raw data file\n",
    "# Import data h5py file\n",
    "file_path = '/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.1. F0 final/TODOS_resampled_5ms_20231115.hdf5'\n",
    "hdf5_file = h5py.File(file_path, 'r')\n",
    "# Get the data set for file bpubmn01__098__SHE\n",
    "test_size_raw = hdf5_file['bpubmn01__098__SHE'][:]\n",
    "# Print shape\n",
    "print(test_size_raw.shape)\n",
    "# And we print the same shape for the test_data array\n",
    "hdf5_file = h5py.File('/mnt/c/Users/Saulo Mendes Santos/OneDrive/Documents/2. LETRAS/0. Doutorado/0. Recherche/1.1. F0 final/TODOS_resampled_5ms_VD-predictions_20231116.hdf5', 'r')\n",
    "# Get the data set for file bpubmn01__098__SHE\n",
    "test_size = hdf5_file['bpubmn01__098__SHE'][:]\n",
    "# Print shape\n",
    "print(test_size.shape)\n",
    "# Print if shapes are the same\n",
    "if test_size_raw.shape[0] == test_size.shape[0]:\n",
    "    print(\"We're good to go!\")\n",
    "else:\n",
    "    print(\"Something is wrong!\")\n",
    "# Close the hdf5 file\n",
    "hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
